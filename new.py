import streamlit as st
import pandas as pd
from class_school_info import SchoolInfo
import init
import llms  # ×”×•×¡×¤×ª ×™×™×‘×•× ×œ××•×“×•×œ llms
import os
from openai import OpenAI
from dotenv import load_dotenv

# ×˜×¢×™× ×ª ××©×ª× ×™ ×”×¡×‘×™×‘×” ××§×•×‘×¥ .env
load_dotenv()

# ×§×‘×œ×ª ×”-API key ××”××©×ª× ×™× ×•×”×’×“×¨×ª ×”×œ×§×•×—
api_key = os.getenv("OPENAI_API_KEY")
if api_key:
    openai_client = OpenAI(api_key=api_key)
else:
    openai_client = OpenAI()  # ×™×ª×›×Ÿ ×©×™×¢×‘×•×“ ×× ×™×© API key ×‘×¡×‘×™×‘×”

# ×˜×¢×™× ×ª ×”× ×ª×•× ×™× - init ×›×‘×¨ ×›×•×œ×œ ××ª set_page_config ×œ×›×Ÿ ××™×Ÿ ×¦×•×¨×š ×œ×§×¨×•× ×œ×” ×©×•×‘
try:
    df = init.init()
except Exception as e:
    st.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ×”× ×ª×•× ×™×: {e}")
    df = pd.DataFrame()

# ×™×¦×™×¨×ª ××©×ª× ×” session state ×œ×©××™×¨×ª ××¦×‘ ×”×¦×’×ª ×”×’×¨×¤×™×
if "show_graphs_state" not in st.session_state:
    st.session_state.show_graphs_state = False

# ×”×•×¡×¤×ª ×ª××™×›×” ×‘-RTL ×•×¢×™×¦×•×‘ ××•×ª××
st.markdown("""
<style>
/* ×ª××™×›×” ×‘-RTL */
h1, h2, h3, h4, h5, h6, p, div {
    text-align: right;
    direction: rtl;
}

/* ×¢×™×¦×•×‘ ×‘×—×™×¨×ª ×‘×™×ª ×¡×¤×¨ ×‘×¨××© ×”×¢××•×“ */
.school-selector {
    background-color: #f8f9fa;
    padding: 20px;
    border-radius: 10px;
    margin-bottom: 30px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    text-align: center;
}

/* ×¢×™×¦×•×‘ ×ª×™×‘×ª ×”×‘×—×™×¨×” */
div[data-testid="stSelectbox"] {
    text-align: right;
    direction: rtl;
    max-width: 400px;
    margin: 0 auto;
}

/* ×¢×™×¦×•×‘ ×”×’×¨×¤×™× */
.stPlotlyChart {
    background-color: white;
    border-radius: 10px;
    padding: 15px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    margin-bottom: 20px;
}

/* ×¢×™×¦×•×‘ ×›×¨×˜×™×¡ ×”×¡×‘×¨ */
.explanation-box {
    background-color: #f8f9fa;
    border-radius: 10px;
    padding: 15px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    margin-top: 10px;
    margin-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

# ×›×•×ª×¨×ª ×”×“×£
st.title("×“××©×‘×•×¨×“ × ×™×ª×•×— × ×ª×•× ×™× ğŸ“Š")

# ××–×•×¨ ×‘×—×™×¨×ª ×‘×™×ª ×”×¡×¤×¨ ×‘×¨××© ×”×¢××•×“
st.markdown('<div class="school-selector">', unsafe_allow_html=True)
st.markdown("<h3 style='margin-bottom: 15px;'>×‘×—×¨ ×‘×™×ª ×¡×¤×¨ ×œ× ×™×ª×•×—</h3>", unsafe_allow_html=True)

if not df.empty and 'school' in df.columns:
    unique_schools = df["school"].unique().tolist()
    selected_school = st.selectbox("×‘×—×¨ ×‘×™×ª ×¡×¤×¨:", unique_schools, key="school_selector")
    filtered_df = df[df['school'] == selected_school] if selected_school else df
else:
    st.warning("×œ× × ××¦××• × ×ª×•× ×™× ×œ×¡×™× ×•×Ÿ")
    filtered_df = df

st.markdown('</div>', unsafe_allow_html=True)


# ×™×¦×™×¨×ª ××©×ª× ×™ ××¦×‘ ×× ×œ× ×§×™×™××™×
if "graph_data" not in st.session_state:
    st.session_state.graph_data = {
        "risc": None,
        "ici": None, 
        "spider": None,
        "selected_school": None
    }

# ×™×¦×™×¨×ª ××©×ª× ×™ ××¦×‘ ×œ×”×¡×‘×¨×™× ×× ×œ× ×§×™×™××™×
if "explanations" not in st.session_state:
    st.session_state.explanations = {
        "risc": "",
        "ici": "",
        "spider": "",
        "combined": "",
        "research": "",  # ×”×•×¡×¤×ª ××©×ª× ×” ×œ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨
        "metrics": ""    # ×”×•×¡×¤×ª ××©×ª× ×” ×œ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
    }

# ×™×¦×™×¨×ª ××©×ª× ×™ ××¦×‘ ×œ×”×¦×’×ª ×”×¡×‘×¨×™×
if "show_explanations" not in st.session_state:
    st.session_state.show_explanations = {
        "risc": False,
        "ici": False,
        "spider": False,
        "combined": False,
        "research": False,  # ×”×•×¡×¤×ª ××©×ª× ×” ×œ×”×¦×’×ª ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨
        "metrics": False    # ×”×•×¡×¤×ª ××©×ª× ×” ×œ×”×¦×’×ª ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
    }

if selected_school and not filtered_df.empty:
    # ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ SchoolInfo
    school_info = SchoolInfo(filtered_df)
    
    #××ª×—×•×œ ×’×¨×¤×™× 
    fig_risc = school_info.get_fig_risc("×—×•×¡×Ÿ")
    fig_ici = school_info.get_fig_ici("××™×§×•×“ ×©×œ×™×˜×”")
    fig_spider = school_info.get_fig_spider()
    
    st.session_state.graph_data["risc"] = {
            "value": school_info.risc,
            "global_avg": st.session_state.global_average["risc"],
            "research_avg": st.session_state.research_average["risc"]
        }
    st.session_state.graph_data["ici"] = {
            "value": school_info.ici,
            "global_avg": st.session_state.global_average["ici"],
            "research_avg": st.session_state.research_average["ici"]
        }
    st.session_state.graph_data["spider"] = {
            "future_negetive_past": {
                "current": school_info.future_negetive_past,
                "global": st.session_state.global_average["future_negetive_past"],
                "research": st.session_state.research_average["future_negetive_past"]
            },
            "future_positive_past": {
                "current": school_info.future_positive_past,
                "global": st.session_state.global_average["future_positive_past"],
                "research": st.session_state.research_average["future_positive_past"]
            },
            "future_fatalic_present": {
                "current": school_info.future_fatalic_present,
                "global": st.session_state.global_average["future_fatalic_present"],
                "research": st.session_state.research_average["future_fatalic_present"]
            },
            "future_hedonistic_present": {
                "current": school_info.future_hedonistic_present,
                "global": st.session_state.global_average["future_hedonistic_present"],
                "research": st.session_state.research_average["future_hedonistic_present"]
            },
            "future_future": {
                "current": school_info.future_future,
                "global": st.session_state.global_average["future_future"],
                "research": st.session_state.research_average["future_future"]
            }
        }
    # 
    # 
    # 
    
    # ×›×¤×ª×•×¨ ×œ×”×¨××•×ª × ×™×ª×•×— ××§×™×£
    if st.button("×”×¨××” ×œ×™ × ×™×ª×•×— ××§×™×£", key="show_combined_explanation"):
            st.session_state.show_explanations["combined"] = not st.session_state.show_explanations["combined"]
            
            # ×× ×¦×¨×™×š ×œ×”×¦×™×’ ×”×¡×‘×¨ ××¡×›× ×•×”×”×¡×‘×¨ ×¨×™×§ - ×§×‘×œ ×”×¡×‘×¨ ×—×“×©
            if st.session_state.show_explanations["combined"] and not st.session_state.explanations["combined"]:
                combined_placeholder = st.empty()
                combined_placeholder.markdown("××™×™×¦×¨ × ×™×ª×•×— ××§×™×£...")
                
                # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××¡×›× ×œ×›×œ ×”×’×¨×¤×™×
                summary_prompt = f"""
                × ×ª×— ××ª ×”× ×ª×•× ×™× ×”×‘××™× ×©×œ ×‘×™×ª ×”×¡×¤×¨ {selected_school} ×•×ª×Ÿ ×”×¡×‘×¨ ×›×•×œ×œ ×¢×œ ×”××©××¢×•×ª ×©×œ×”×:
                
                1. ×—×•×¡×Ÿ (RISC): 
                   ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('risc', {}).get('value', '×—×¡×¨')}
                   ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('risc', {}).get('global_avg', '×—×¡×¨')}
                
                2. ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™ (ICI):
                   ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('ici', {}).get('value', '×—×¡×¨')}
                   ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('ici', {}).get('global_avg', '×—×¡×¨')}
                
                3. ×ª×¤×™×¡×•×ª ×–××Ÿ: [× ×ª×•× ×™ ×ª×¤×™×¡×•×ª ×”×–××Ÿ ×”×©×•× ×•×ª]
                
                ×”×ª×™×™×—×¡ ×œ××©××¢×•×ª ×”××©×•×œ×‘×ª ×©×œ ×›×œ ×”××“×“×™× ×•×”×§×©×¨ ×‘×™× ×™×”×. ×ª×Ÿ ×©××œ×•×ª ×× ×—×•×ª ×œ×× ×”×œ ×‘×™×ª ×”×¡×¤×¨ ×©×™×¢×–×¨×• ×œ×• ×œ×©×¤×¨ ××ª ×”××¦×‘.
                """
                
                # ××¢×¨×›×ª ×¤×¨×•××¤×˜ ×œ× ×™×ª×•×— ××¡×›×
                system_prompt = """××ª×” ×™×•×¢×¥ ×—×™× ×•×›×™ ××•××—×” ×‘× ×™×ª×•×— × ×ª×•× ×™× ×¤×¡×™×›×•×œ×•×’×™×™× ×©×œ ×ª×œ××™×“×™×. 
                ×”×¡×‘×¨ ×‘×‘×§×©×” ××ª ×”××©××¢×•×ª ×”××©×•×œ×‘×ª ×©×œ ×›×œ ×”××“×“×™× ×”×‘××™× ×¢×‘×•×¨ ×‘×™×ª ×”×¡×¤×¨ ×•×”×§×©×¨ ×‘×™× ×™×”×.
                
                ××“×“ ×”×—×•×¡×Ÿ (RISC) - ××•×“×“ ××ª ×™×›×•×œ×ª ×”×ª×œ××™×“×™× ×œ×”×ª××•×“×“ ×¢× ××ª×’×¨×™× ×•××¦×‘×™ ×œ×—×¥. ×¢×¨×›×™× ×’×‘×•×”×™× ××¢×™×“×™× ×¢×œ ×—×•×¡×Ÿ ×’×‘×•×”.
                
                ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™ (ICI) - ××•×“×“ ××ª ×”×××•× ×” ×©×œ ×”×ª×œ××™×“×™× ×‘×™×›×•×œ×ª× ×œ×©×œ×•×˜ ×‘×—×™×™×”×. ×¢×¨×›×™× ×’×‘×•×”×™× ××¢×™×“×™× ×¢×œ ×ª×—×•×©×ª ×©×œ×™×˜×” ×¢×¦××™×ª ×—×–×§×” ×™×•×ª×¨.
                
                ×ª×¤×™×¡×•×ª ×–××Ÿ - ×—××™×©×” ×××“×™×:
                1. ×¢×‘×¨ ×©×œ×™×œ×™ - ×ª×¤×™×¡×” ×©×œ×™×œ×™×ª ×©×œ ×”×¢×‘×¨, ×˜×¨××•××•×ª ×•×—×•×•×™×•×ª ×§×©×•×ª
                2. ×¢×‘×¨ ×—×™×•×‘×™ - ×ª×¤×™×¡×” ×—×™×•×‘×™×ª ×©×œ ×”×¢×‘×¨, × ×•×¡×˜×œ×’×™×” ×•×–×›×¨×•× ×•×ª ×˜×•×‘×™×
                3. ×”×•×•×” ×“×˜×¨××™× ×™×¡×˜×™ - ×ª×¤×™×¡×” ×¤×˜×œ×™×¡×˜×™×ª ×©×œ ×”×”×•×•×”, ×—×•×¡×¨ ×©×œ×™×˜×”
                4. ×”×•×•×” ×”×“×•× ×™×¡×˜×™ - ×ª×¤×™×¡×ª ×”×•×•×” ×”×“×•× ×™×¡×˜×™×ª, ×—×™×¤×•×© ×”× ××•×ª ××™×™×“×™×•×ª
                5. ×¢×ª×™×“ - ×™×›×•×œ×ª ×ª×›× ×•×Ÿ ×§×“×™××”, ×“×—×™×™×ª ×¡×™×¤×•×§×™×, ×”×¦×‘×ª ××˜×¨×•×ª
                
                ×¡×™×™× ××ª ×”×”×¡×‘×¨ ×‘×©××œ×•×ª ×× ×—×•×ª ×œ×× ×”×œ ×‘×™×ª ×”×¡×¤×¨ ×©×™×›×•×œ×•×ª ×œ×¢×•×“×“ ××•×ª×• ×œ×—×©×•×‘ ×¢×œ ×©×™×¤×•×¨ ×”××¦×‘ ×©×œ×•.
                ×œ×“×•×’××”: '××™×š ×›×™×•× ×‘×™×ª ×”×¡×¤×¨ ××¢×•×“×“ ×ª×œ××™×“×™× ×œ×”×¨×’×™×© ×‘×¢×œ×•×ª ×¢×œ ×”××¢×©×™× ×©×œ×”×?', '×”×× ×™×© ××§×•××•×ª × ×•×¡×¤×™× ×©×”×™×™×ª ××©×œ×‘ ×™×›×•×œ×ª ×œ×§×—×ª ×‘×¢×œ×•×ª ×¢×œ ×”×¦×œ×—×•×ª ××• ×›×©×œ×•× ×•×ª ×•××™×“×ª ×”×”×©×¤×¢×” ×”××™×©×™×ª ×©×œ ×”×ª×œ××™×“ ×¢×œ×™×”×Ÿ?'
                """
                
                try:
                    # ×§×¨×™××” ×œ××•×“×œ ×”×©×¤×” ×œ×§×‘×œ×ª ×”×¡×‘×¨ ××¡×›×
                    response_stream = openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": summary_prompt}
                        ],
                        temperature=0.5,
                        max_tokens=1500,
                        stream=True
                    )
                    
                    full_explanation = ""
                    
                    # ×¢×“×›×•×Ÿ ×ª×•×›×Ÿ ×”×”×¡×‘×¨ ×‘×–××Ÿ ×§×‘×œ×ª ×ª×©×•×‘×•×ª ××”××•×“×œ
                    for chunk in response_stream:
                        if chunk.choices and hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                            content = chunk.choices[0].delta.content
                            if content:
                                full_explanation += content
                                combined_placeholder.markdown(full_explanation + "â–Œ")
                    
                    # ×ª×¦×•×’×” ×¡×•×¤×™×ª ×©×œ ×”×”×¡×‘×¨ ×”××œ×
                    combined_placeholder.markdown(full_explanation)
                    
                    # ×©××™×¨×ª ×”×”×¡×‘×¨ ×”××¡×›×
                    st.session_state.explanations["combined"] = full_explanation
                    
                except Exception as e:
                    error_msg = f"×œ× ×”×¦×œ×—× ×• ×œ×™×™×¦×¨ × ×™×ª×•×— ××§×™×£. ×©×’×™××”: {str(e)}"
                    combined_placeholder.error(error_msg)
                    st.session_state.explanations["combined"] = error_msg
    
    # ×”×•×¡×¤×ª ×›×¤×ª×•×¨ ×œ×”×¦×’×ª ×”××œ×¦×•×ª ×©×™×¤×•×¨ ×¡×¤×¦×™×¤×™×•×ª
    if st.button("×‘××” ×”×›×™ ×›×“××™ ×œ×™ ×œ×”×©×ª×¤×¨", key="improvement_recommendation"):
        # ×™×¦×™×¨×ª ××©×ª× ×” ××¦×‘ ×œ×”××œ×¦×•×ª ×©×™×¤×•×¨ ×× ×œ× ×§×™×™×
        if "improvement_recommendation" not in st.session_state.explanations:
            st.session_state.explanations["improvement_recommendation"] = ""
        
        improvement_placeholder = st.empty()
        improvement_placeholder.markdown("××™×™×¦×¨ ×”××œ×¦×•×ª ×©×™×¤×•×¨ ××•×ª×××•×ª ××™×©×™×ª...")
        
        # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ×œ×”××œ×¦×•×ª ×©×™×¤×•×¨
        improvement_prompt = f"""
        ×‘×ª×•×¨ ×™×•×¢×¥ ×—×™× ×•×›×™, ×”×›×Ÿ ×”××œ×¦×” ××¤×•×¨×˜×ª ×•×× ×•××§×ª ×œ×× ×”×œ ×‘×™×ª ×”×¡×¤×¨ {selected_school} ×¢×œ ×¡××š ×”× ×ª×•× ×™× ×”×‘××™×:
        
        ×”××“×“ ×”×—×œ×© ×‘×™×•×ª×¨ ×‘×‘×™×ª ×”×¡×¤×¨ ×”×•×: {school_info.worst_anigma_name}
        ×”×”×™×’×“ ×”×‘×¢×™×™×ª×™ ×‘×™×•×ª×¨ ×‘××“×“ ×–×” ×”×•×: {school_info.worst_heg1_text}
        
        ×›×ª×•×‘ ×”××œ×¦×” ××¤×•×¨×˜×ª, ×× ×•××¡×ª ×•×× ×•××§×ª ×œ×× ×”×œ, ×ª×•×š ×”×ª×™×™×—×¡×•×ª ×¡×¤×¦×™×¤×™×ª ×œ××“×“ ×”×—×œ×© ×•×œ×”×™×’×“ ×”×‘×¢×™×™×ª×™.
        ×ª×Ÿ ×“×•×’×××•×ª ×§×•× ×§×¨×˜×™×•×ª ×œ×¤×¢×•×œ×•×ª ×©×”×× ×”×œ ×™×›×•×œ ×œ×‘×¦×¢ ×›×“×™ ×œ×©×¤×¨ ××ª ×”××“×“ ×”×¡×¤×¦×™×¤×™ ×”×–×”.
        """
        
        # ××¢×¨×›×ª ×¤×¨×•××¤×˜ ×œ×”××œ×¦×•×ª ×©×™×¤×•×¨
        improvement_system_prompt = """
        ××ª×” ×™×•×¢×¥ ×—×™× ×•×›×™ ××•××—×” ×‘× ×™×ª×•×— × ×ª×•× ×™× ×¤×¡×™×›×•×œ×•×’×™×™× ×©×œ ×ª×œ××™×“×™× ×•×‘×™×ª ×¡×¤×¨. 
        
        ×‘×”××œ×¦×” ×©×œ×š, ×”×ª×™×™×—×¡ ×œ× ×§×•×“×•×ª ×”×‘××•×ª:
        1. ×ª×Ÿ ×”×¡×‘×¨ ×‘×¨×•×¨ ×•×™×“×™×“×•×ª×™ ×¢×œ ×”××“×“ ×”×—×œ×© ×•××©××¢×•×ª×• ×‘×”×§×©×¨ ×”×—×™× ×•×›×™
        2. ×”×¡×‘×¨ ××ª ×”×”×©×œ×›×•×ª ×©×œ ×”××“×“ ×”×—×œ×© ×¢×œ ×”×ª×œ××™×“×™× ×•×”×¡×‘×™×‘×” ×”×œ×™××•×“×™×ª
        3. ×ª×Ÿ ×›××” ×©××œ×•×ª ×œ×—×©×™×‘×” ×œ×× ×”×œ ×©×™×›×•×œ×•×ª ×œ×’×¨×•× ×œ×• ×œ×”×‘×™×Ÿ ××” ×§×•×¨×” ××¦×œ×• ×‘×‘×™×ª ×”×¡×¤×¨ ×•××™×š ××¤×©×¨ ×œ×©×¤×¨ ××ª ×”××¦×‘       
        
        ××œ ×ª×ª×Ÿ ×”××œ×¦×•×ª ×•××œ ×ª×¡×›× ××ª ×”×©×™×—×” .   
        """
        
        try:
            # ×§×¨×™××” ×œ××•×“×œ ×”×©×¤×” ×œ×§×‘×œ×ª ×”××œ×¦×•×ª ×©×™×¤×•×¨
            response_stream = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": improvement_system_prompt},
                    {"role": "user", "content": improvement_prompt}
                ],
                temperature=0.5,
                max_tokens=1500,
                stream=True
            )
            
            full_recommendation = ""
            
            # ×¢×“×›×•×Ÿ ×ª×•×›×Ÿ ×”×”××œ×¦×•×ª ×‘×–××Ÿ ×§×‘×œ×ª ×ª×©×•×‘×•×ª ××”××•×“×œ
            for chunk in response_stream:
                if chunk.choices and hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                    content = chunk.choices[0].delta.content
                    if content:
                        full_recommendation += content
                        improvement_placeholder.markdown(full_recommendation + "â–Œ")
            
            # ×ª×¦×•×’×” ×¡×•×¤×™×ª ×©×œ ×”×”××œ×¦×•×ª ×”××œ××•×ª ×‘×ª×•×š ××¡×’×¨×ª ××¢×•×¦×‘×ª
            improvement_placeholder.markdown(f"""
            <div class="explanation-box">
                <h3>×”××œ×¦×•×ª ×œ×©×™×¤×•×¨ ×‘×™×ª ×”×¡×¤×¨</h3>
                {full_recommendation}
            </div>
            """, unsafe_allow_html=True)
            
            # ×©××™×¨×ª ×”×”××œ×¦×•×ª
            st.session_state.explanations["improvement_recommendation"] = full_recommendation
            
        except Exception as e:
            error_msg = f"×œ× ×”×¦×œ×—× ×• ×œ×™×™×¦×¨ ×”××œ×¦×•×ª ×©×™×¤×•×¨. ×©×’×™××”: {str(e)}"
            improvement_placeholder.error(error_msg)
            st.session_state.explanations["improvement_recommendation"] = error_msg
                  
    
# ×”×•×¡×¤×ª ×›×¤×ª×•×¨ "×× ×™ ×¨×•×¦×” ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨", ×¤×•× ×§×¦×™×” ×•×”×¦×’×ª ×ª×•×›×Ÿ ×”×”×¡×‘×¨
if st.button("×× ×™ ×¨×•×¦×” ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨", key="research_explanation_button"):
    st.session_state.show_explanations["research"] = True
    
    # ×× ×¦×¨×™×š ×œ×”×¦×™×’ ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨ ×•×”×”×¡×‘×¨ ×¨×™×§ - ×§×‘×œ ×”×¡×‘×¨ ×—×“×©
    if st.session_state.show_explanations["research"] and not st.session_state.explanations["research"]:
        research_placeholder = st.empty()
        research_placeholder.markdown("××™×™×¦×¨ ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨...")
        
        # ××™×“×¢ ×¢×œ ×”××—×§×¨
        research_info = """
        ××˜×¨×ª ×”×¦×™×¨ ×”×× ×˜×œ×™ ×‘×ª×•×›× ×™×ª ×”×”×™×™ ×˜×§ ×”×™× ×œ×¤×ª×— ×“×¤×•×¡ ×—×©×™×‘×” ××ª×¤×ª×— ××©×¨ ×™×ª×¨×•× ××©××¢×•×ª×™×ª ×œ×§×™×“×•×
        ×ª×œ××™×“×™ ×—×˜×™×‘×•×ª ×‘×™× ×™×™× ×•×ª×™×›×•× ×™× ××”×¤×¨×™×¤×¨×™×” (××“×“ ×˜×™×¤×•×— 6-10) ×œ×§×¨×™×™×¨×•×ª ×”×™×™-×˜×§ ×‘×™×©×¨××œ. ×”×ª×•×›× ×™×ª ×”×™×
        ×‘×¢×œ×ª ×’×™×©×” ×”×•×œ×™×¡×˜×™×ª, ×”×›×•×œ×œ×ª ×œ× ×¨×§ ×ª×œ××™×“×™× ××œ× ×’× ×”×›×©×¨×ª ×× ×©×™ ×—×™× ×•×š ×›×¡×•×›× ×™ ×©×™× ×•×™ ×•××¢×¨×‘×ª ××ª
        ×”×× ×”×™×’×•×ª ×”×‘×™×ª ×¡×¤×¨×™×ª ×‘×ª×”×œ×™×š ×¢×œ ×× ×ª ×œ×™×¦×•×¨ ××™×§×¡×•× ×”××™××¤×§×˜ ×©×œ ×”×ª×•×›× ×™×ª. ×œ×¦×“ ×¡×“× ××•×ª ×œ×¤×™×ª×•×— ×“×¤×•×¡
        ×—×©×™×‘×” ××ª×¤×ª×—, ×”×ª×•×›× ×™×ª ××©×œ×‘×ª ×—×•×•×™×” ×™×–××™×ª ××¢×©×™×ª ×¢× ×¤×™×ª×•×— ×“×¤×•×¡ ×—×©×™×‘×” ××ª×¤×ª×—. ×”×ª×œ××™×“×™×
        ××©×ª×ª×¤×™× ×‘×¤×¢×™×œ×•×™×•×ª ×•×ª×—×¨×•×™×•×ª ×“××•×™×•×ª ×¡×˜××¨×˜××¤ ×ª×•×š ×©×”× ×œ×•××“×™× ×©× ×™×ª×Ÿ ×œ×¤×ª×— ××ª ×”×™×›×•×œ×•×ª ×©×œ×”×
        ×‘×××¦×¢×•×ª ××¡×™×¨×•×ª ×•×¢×‘×•×“×” ×§×©×”. ×”×ª×•×›× ×™×ª ××œ×•×•×” ×¢×œ ×™×“×™ ×—×‘×¨×•×ª ×˜×›× ×•×œ×•×’×™×” ×©×•× ×•×ª ×›××• ×’×•×’×œ, ××™×§×¨×•×¡×•×¤×˜, ×××–×•×Ÿ
        ×•××™× ×˜×œ, ×™×—×“ ×¢× ×©×•×ª×¤×™× ×‘××’×–×¨ ×”×—×™× ×•×›×™ ×•×”×¦×™×‘×•×¨×™.
        ×—×–×•×Ÿ ×”×ª×•×›× ×™×ª
        ×™×¦×™×¨×ª ×ª××•× ×ª ×¢×ª×™×“ ×©×œ ××¨×—×‘ ×”×–×“×× ×•×™×•×ª ×¢×ª×™×“×™×•×ª ×‘×”×™×™×˜×§ ×•×¤×™×ª×•×— ×’×™×©×•×ª ×—×™×•×‘×™×•×ª ×›×œ×¤×™ ×œ××™×“×” ×•×”×ª×¤×ª×—×•×ª
        ××™×©×™×ª (×›×•×œ×œ ×‘×™×˜×—×•×Ÿ ×¢×¦××™, ×ª×—×•×©×ª ××¡×•×’×œ×•×ª, ×—×•×¡×Ÿ ×•××•×˜×™×‘×¦×™×” ×œ×”×™×›× ×¡ ×œ×”×™×™×˜×§).
        ×§×”×œ ×”×™×¢×“
        ×ª×œ××™×“×™× ×‘×›×™×ª×•×ª ×—' ×•-×™' ×‘-93 ×‘×ª×™ ×¡×¤×¨ ×‘××“×“×™ ×˜×™×¤×•×— 6-10
        """
        
        # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ×œ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨
        if selected_school:
            school_context = f"""
            × ×ª×•× ×™ ×‘×™×ª ×”×¡×¤×¨ {selected_school}:
            
            1. ×—×•×¡×Ÿ (RISC): 
            ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('risc', {}).get('value', '×—×¡×¨')}
            ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('risc', {}).get('global_avg', '×—×¡×¨')}
            
            2. ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™ (ICI):
            ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('ici', {}).get('value', '×—×¡×¨')}
            ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('ici', {}).get('global_avg', '×—×¡×¨')}
            """
        else:
            school_context = "××™×Ÿ × ×ª×•× ×™× ×–××™× ×™× ×œ×‘×™×ª ×¡×¤×¨ ×¡×¤×¦×™×¤×™ ×›×¨×’×¢."
            
        # ××¢×¨×›×ª ×¤×¨×•××¤×˜ ×œ×”×¡×‘×¨ ×”××—×§×¨
        system_prompt = """
        ××ª×” ××•××—×” ×—×™× ×•×›×™ ×”××¡×‘×™×¨ ××—×§×¨×™× ×¤×¡×™×›×•×œ×•×’×™×™× ×•×—×™× ×•×›×™×™×. 
        
        ×”×¡×‘×¨ ××ª ×”××—×§×¨ ×‘××•×¤×Ÿ ×ª××¦×™×ª×™ ×•× ×—××“, ×ª×•×š ×”×ª×™×™×—×¡×•×ª ×œ× ×§×•×“×•×ª ×”×‘××•×ª:
        1. ××˜×¨×•×ª ×”××—×§×¨ ×•×”×¨×§×¢ ×œ×•
        2. ×”×’×™×©×” ×”×—×™× ×•×›×™×ª ×•×”×¤×¡×™×›×•×œ×•×’×™×ª (×›×•×œ×œ ×“×¤×•×¡ ×—×©×™×‘×” ××ª×¤×ª×—)
        3. ×”×§×©×¨ ×‘×™×Ÿ ×”××“×“×™× ×”× ××“×“×™× (×—×•×¡×Ÿ, ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™, ×ª×¤×™×¡×•×ª ×–××Ÿ) ×•×‘×™×Ÿ ×”×¦×œ×—×” ×‘×œ×™××•×“×™× ×•×‘×ª×—×•× ×”×”×™×™×˜×§
        4. ××©××¢×•×ª ×”× ×ª×•× ×™× ×¢×‘×•×¨ ×‘×™×ª ×”×¡×¤×¨ ×”×¡×¤×¦×™×¤×™ (×× ×™×©)
        
        ×”×¡×‘×¨ ××ª ×”××™×“×¢ ×‘×¦×•×¨×” ×™×“×™×“×•×ª×™×ª, ××§×¦×•×¢×™×ª ×•××›×‘×“×ª. ×”×ª×× ××ª ×”×”×¡×‘×¨ ×œ×× ×”×œ×™× ×•×× ×©×™ ×—×™× ×•×š.
×œ×œ× ×œ×¡×›× ××ª ×”×©×™×—×” ×•×œ× ×œ××—×œ ×‘×”×¦×œ×—×” ××• ×‘×‘×¨×›×” . 
"""
        
        research_prompt = f"""
        ×”×¡×‘×¨ ×‘×‘×§×©×” ××ª ×”××—×§×¨ ×”×‘× ×‘×”×§×©×¨ ×©×œ ×‘×™×ª ×”×¡×¤×¨ ×•××“×“×™ ×”×—×•×¡×Ÿ, ××™×§×•×“ ×”×©×œ×™×˜×” ×”×¤× ×™××™ ×•×ª×¤×™×¡×•×ª ×”×–××Ÿ:
        
        {research_info}
        
        {school_context}
        
        ×‘×”×¡×‘×¨ ×©×œ×š, ×”×ª×™×™×—×¡ ×œ×—×©×™×‘×•×ª ×©×œ ××“×“×™ ×”×—×•×¡×Ÿ, ××™×§×•×“ ×”×©×œ×™×˜×” ×”×¤× ×™××™ ×•×ª×¤×™×¡×•×ª ×”×–××Ÿ ×‘×”×§×©×¨ ×©×œ ×”×ª×•×›× ×™×ª,
        ×•×›×™×¦×“ ×”× ××©×¤×™×¢×™× ×¢×œ ×”×¦×œ×—×” ××§×“××™×ª ×•××§×¦×•×¢×™×ª ×‘×ª×—×•× ×”×”×™×™×˜×§.
        """
        
        try:
            # ×§×¨×™××” ×œ××•×“×œ ×”×©×¤×” ×œ×§×‘×œ×ª ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨
            response_stream = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": research_prompt}
                ],
                temperature=0.5,
                max_tokens=1500,
                stream=True
            )
            
            full_explanation = ""
            
            # ×¢×“×›×•×Ÿ ×ª×•×›×Ÿ ×”×”×¡×‘×¨ ×‘×–××Ÿ ×§×‘×œ×ª ×ª×©×•×‘×•×ª ××”××•×“×œ
            for chunk in response_stream:
                if chunk.choices and hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                    content = chunk.choices[0].delta.content
                    if content:
                        full_explanation += content
                        research_placeholder.markdown(full_explanation + "â–Œ")
            
            # ×ª×¦×•×’×” ×¡×•×¤×™×ª ×©×œ ×”×”×¡×‘×¨ ×”××œ× ×‘×ª×•×š ××¡×’×¨×ª
            research_placeholder.markdown(f"""
            <div class="explanation-box">
                <h3>×”×¡×‘×¨ ×¢×œ ×”××—×§×¨</h3>
                {full_explanation}
            </div>
            """, unsafe_allow_html=True)
            
            # ×©××™×¨×ª ×”×”×¡×‘×¨ ×¢×œ ×”××—×§×¨
            st.session_state.explanations["research"] = full_explanation
            
        except Exception as e:
            error_msg = f"×œ× ×”×¦×œ×—× ×• ×œ×™×™×¦×¨ ×”×¡×‘×¨ ×¢×œ ×”××—×§×¨. ×©×’×™××”: {str(e)}"
            research_placeholder.error(error_msg)
            st.session_state.explanations["research"] = error_msg
    else:
        # ×”×¦×’×ª ×”×”×¡×‘×¨ ×”×©××•×¨
        st.markdown(f"""
        <div class="explanation-box">
            <h3>×”×¡×‘×¨ ×¢×œ ×”××—×§×¨</h3>
            {st.session_state.explanations["research"]}
        </div>
        """, unsafe_allow_html=True)
             

    
    
    
    # 
    # 
    # 
    # ×’×ª ×”×’×¨×¤×™× ×‘×˜×•×¨×™×
    # ×‘×“×™×§×” ×× ×™×© ×œ×—×™×¦×” ×¢×œ ×›×¤×ª×•×¨ ×”×¦×’×ª ×’×¨×¤×™× ××• ×× ×”×’×¨×¤×™× ×›×‘×¨ ×”×•×¦×’×• ×§×•×“×
if st.button("×”×¦×’ ×œ×™ ×’×¨×¤×™×") or st.session_state.show_graphs_state:
        # ×¢×“×›×•×Ÿ ×”××¦×‘ ×œ×–×›×•×¨ ×©×”×’×¨×¤×™× ×”×•×¦×’×•
        st.session_state.show_graphs_state = True
        
        st.markdown("### ××“×“ ×—×•×¡×Ÿ")
        fig_risc = school_info.get_fig_risc("×—×•×¡×Ÿ")
        st.plotly_chart(fig_risc, use_container_width=True)
        
        # ×©××™×¨×ª × ×ª×•× ×™ ×’×¨×£ ×—×•×¡×Ÿ ×œ××¦×‘
        st.session_state.graph_data["risc"] = {
            "value": school_info.risc,
            "global_avg": st.session_state.global_average["risc"],
            "research_avg": st.session_state.research_average["risc"]
        }
        
        
        st.markdown("### ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™")
        fig_ici = school_info.get_fig_ici("××™×§×•×“ ×©×œ×™×˜×”")
        st.plotly_chart(fig_ici, use_container_width=True)
        
        # ×©××™×¨×ª × ×ª×•× ×™ ×’×¨×£ ××™×§×•×“ ×©×œ×™×˜×” ×œ××¦×‘
        st.session_state.graph_data["ici"] = {
            "value": school_info.ici,
            "global_avg": st.session_state.global_average["ici"],
            "research_avg": st.session_state.research_average["ici"]
        }
        
        
        st.markdown("### ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×××“×™ ×–××Ÿ")
        fig_spider = school_info.get_fig_spider()
        st.plotly_chart(fig_spider, use_container_width=True)
        
        # ×©××™×¨×ª × ×ª×•× ×™ ×’×¨×£ ×¢×›×‘×™×© ×œ××¦×‘
        anigmas_dict = school_info.return_anigmas_result_as_dict()
        st.session_state.graph_data["spider"] = {
            "future_negetive_past": {
                "current": anigmas_dict["future_negetive_past"],
                "global": st.session_state.global_average["future_negetive_past"],
                "research": st.session_state.research_average["future_negetive_past"]
            },
            "future_positive_past": {
                "current": anigmas_dict["future_positive_past"],
                "global": st.session_state.global_average["future_positive_past"],
                "research": st.session_state.research_average["future_positive_past"]
            },
            "future_fatalic_present": {
                "current": anigmas_dict["future_fatalic_present"],
                "global": st.session_state.global_average["future_fatalic_present"],
                "research": st.session_state.research_average["future_fatalic_present"]
            },
            "future_hedonistic_present": {
                "current": anigmas_dict["future_hedonistic_present"],
                "global": st.session_state.global_average["future_hedonistic_present"],
                "research": st.session_state.research_average["future_hedonistic_present"]
            },
            "future_future": {
                "current": anigmas_dict["future_future"],
                "global": st.session_state.global_average["future_future"],
                "research": st.session_state.research_average["future_future"]
            }
        }
        
# ×”×•×¡×¤×ª ×›×¤×ª×•×¨ "×”×¡×‘×¨ ×œ×™ ×¢×•×“ ×¢×œ ×”××“×“×™×"
if st.button("×”×¡×‘×¨ ×œ×™ ×¢×•×“ ×¢×œ ×”××“×“×™×"):
    st.session_state.show_explanations["metrics"] = True
    
    # ×× ×¦×¨×™×š ×œ×”×¦×™×’ ×”×¡×‘×¨ ×¢×œ ×”××“×“×™× ×•×”×”×¡×‘×¨ ×¨×™×§ - ×§×‘×œ ×”×¡×‘×¨ ×—×“×©
    if st.session_state.show_explanations["metrics"] and not st.session_state.explanations["metrics"]:
        metrics_placeholder = st.empty()
        metrics_placeholder.markdown("××™×™×¦×¨ ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×...")
        
        # ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ×œ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
        metrics_prompt = f"""
        ×”×¡×‘×¨ ××ª ×”××“×“×™× ×”×‘××™× ×‘×”×§×©×¨ ×©×œ × ×ª×•× ×™ ×‘×™×ª ×”×¡×¤×¨ {selected_school}:
        
        1. ×—×•×¡×Ÿ (RISC): 
           ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('risc', {}).get('value', '×—×¡×¨')}
           ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('risc', {}).get('global_avg', '×—×¡×¨')}
        
        2. ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™ (ICI):
           ×¢×¨×š × ×•×›×—×™: {st.session_state.graph_data.get('ici', {}).get('value', '×—×¡×¨')}
           ×××•×¦×¢ ××¨×¦×™: {st.session_state.graph_data.get('ici', {}).get('global_avg', '×—×¡×¨')}
        
        3. ×ª×¤×™×¡×•×ª ×–××Ÿ: [× ×ª×•× ×™ ×ª×¤×™×¡×•×ª ×”×–××Ÿ ×”×©×•× ×•×ª]
        
        ×”×¡×‘×¨ ××ª ×”××©××¢×•×ª ×©×œ ×›×œ ××“×“ ×•×›×™×¦×“ ×”×•× ×¨×œ×•×•× ×˜×™ ×œ× ×ª×•× ×™ ×‘×™×ª ×”×¡×¤×¨. ×ª×Ÿ ×“×•×’×××•×ª ××¢×©×™×•×ª ×œ×©×™××•×© ×‘××“×“×™× ××œ×” ×œ×©×™×¤×•×¨ ×”××¦×‘ ×‘×‘×™×ª ×”×¡×¤×¨.
        """
        
        # ××¢×¨×›×ª ×¤×¨×•××¤×˜ ×œ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
        system_prompt = """××ª×” ×™×•×¢×¥ ×—×™× ×•×›×™ ××•××—×” ×‘× ×™×ª×•×— × ×ª×•× ×™× ×¤×¡×™×›×•×œ×•×’×™×™× ×©×œ ×ª×œ××™×“×™×. 
        ×”×¡×‘×¨ ×‘×‘×§×©×” ××ª ×”××©××¢×•×ª ×©×œ ×”××“×“×™× ×”×‘××™× ×¢×‘×•×¨ ×‘×™×ª ×”×¡×¤×¨:
        
        ××“×“ ×”×—×•×¡×Ÿ (RISC) - ××•×“×“ ××ª ×™×›×•×œ×ª ×”×ª×œ××™×“×™× ×œ×”×ª××•×“×“ ×¢× ××ª×’×¨×™× ×•××¦×‘×™ ×œ×—×¥. ×¢×¨×›×™× ×’×‘×•×”×™× ××¢×™×“×™× ×¢×œ ×—×•×¡×Ÿ ×’×‘×•×”.
        
        ××™×§×•×“ ×©×œ×™×˜×” ×¤× ×™××™ (ICI) - ××•×“×“ ××ª ×”×××•× ×” ×©×œ ×”×ª×œ××™×“×™× ×‘×™×›×•×œ×ª× ×œ×©×œ×•×˜ ×‘×—×™×™×”×. ×¢×¨×›×™× ×’×‘×•×”×™× ××¢×™×“×™× ×¢×œ ×ª×—×•×©×ª ×©×œ×™×˜×” ×¢×¦××™×ª ×—×–×§×” ×™×•×ª×¨.
        
        ×ª×¤×™×¡×•×ª ×–××Ÿ - ×—××™×©×” ×××“×™×:
        1. ×¢×‘×¨ ×©×œ×™×œ×™ - ×ª×¤×™×¡×” ×©×œ×™×œ×™×ª ×©×œ ×”×¢×‘×¨, ×˜×¨××•××•×ª ×•×—×•×•×™×•×ª ×§×©×•×ª
        2. ×¢×‘×¨ ×—×™×•×‘×™ - ×ª×¤×™×¡×” ×—×™×•×‘×™×ª ×©×œ ×”×¢×‘×¨, × ×•×¡×˜×œ×’×™×” ×•×–×›×¨×•× ×•×ª ×˜×•×‘×™×
        3. ×”×•×•×” ×“×˜×¨××™× ×™×¡×˜×™ - ×ª×¤×™×¡×” ×¤×˜×œ×™×¡×˜×™×ª ×©×œ ×”×”×•×•×”, ×—×•×¡×¨ ×©×œ×™×˜×”
        4. ×”×•×•×” ×”×“×•× ×™×¡×˜×™ - ×ª×¤×™×¡×ª ×”×•×•×” ×”×“×•× ×™×¡×˜×™×ª, ×—×™×¤×•×© ×”× ××•×ª ××™×™×“×™×•×ª
        5. ×¢×ª×™×“ - ×™×›×•×œ×ª ×ª×›× ×•×Ÿ ×§×“×™××”, ×“×—×™×™×ª ×¡×™×¤×•×§×™×, ×”×¦×‘×ª ××˜×¨×•×ª
        
        ×”×¡×‘×¨ ××ª ×”××“×“×™× ×‘×¦×•×¨×” ×‘×¨×•×¨×” ×•××¢××™×§×”, ×ª×•×š ××ª×Ÿ ×“×•×’×××•×ª ××¢×©×™×•×ª ×œ×©×™××•×© ×‘×”×.
        """
        
        try:
            # ×§×¨×™××” ×œ××•×“×œ ×”×©×¤×” ×œ×§×‘×œ×ª ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
            response_stream = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": metrics_prompt}
                ],
                temperature=0.5,
                max_tokens=1500,
                stream=True
            )
            
            full_explanation = ""
            
            # ×¢×“×›×•×Ÿ ×ª×•×›×Ÿ ×”×”×¡×‘×¨ ×‘×–××Ÿ ×§×‘×œ×ª ×ª×©×•×‘×•×ª ××”××•×“×œ
            for chunk in response_stream:
                if chunk.choices and hasattr(chunk.choices[0], "delta") and hasattr(chunk.choices[0].delta, "content"):
                    content = chunk.choices[0].delta.content
                    if content:
                        full_explanation += content
                        metrics_placeholder.markdown(full_explanation + "â–Œ")
            
            # ×ª×¦×•×’×” ×¡×•×¤×™×ª ×©×œ ×”×”×¡×‘×¨ ×”××œ×
            metrics_placeholder.markdown(full_explanation)
            
            # ×©××™×¨×ª ×”×”×¡×‘×¨ ×¢×œ ×”××“×“×™×
            st.session_state.explanations["metrics"] = full_explanation
            
        except Exception as e:
            error_msg = f"×œ× ×”×¦×œ×—× ×• ×œ×™×™×¦×¨ ×”×¡×‘×¨ ×¢×œ ×”××“×“×™×. ×©×’×™××”: {str(e)}"
            metrics_placeholder.error(error_msg)
            st.session_state.explanations["metrics"] = error_msg
    else:
        # ×”×¦×’×ª ×”×”×¡×‘×¨ ×”×©××•×¨
        st.markdown(f"""
        <div class="explanation-box">
            <h3>×”×¡×‘×¨ ×¢×œ ×”××“×“×™×</h3>
            {st.session_state.explanations["metrics"]}
        </div>
        """, unsafe_allow_html=True)

